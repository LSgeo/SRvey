{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert raster to tiled ML-ready data\n",
    "\n",
    "ers and tif files are common for geoscience. We need a quick way to tile these and save them to our standard numpy/folder tile dataset.\n",
    "\n",
    "This notebook defines functions which:\n",
    "1. convert an ers/tif to a pytorch tensor\n",
    "1. pads any nan areas with reflection padding \n",
    "1. unfolds the tensor in each direction (read torch .fold() / .unfold())\n",
    "1. stacks those into a \"batch\" of tiles\n",
    "1. generates a selection of indices for validation and training data\n",
    "1. saves each to a seperate train/val folder\n",
    "1. Generates some QA/QC figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import torch\n",
    "import tifffile\n",
    "from PIL import Image\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(levelname)s:%(asctime)s: %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"##### Starting new log\")\n",
    "\n",
    "class Norm:\n",
    "    def __init__(self, t_file_path):\n",
    "        \"\"\"Load a pre-fit sklearn Transformer to normalise input array\"\"\"\n",
    "\n",
    "        self.transformer = joblib.load(t_file_path)\n",
    "        logger.info(f\"Using {t_file_path} to transform your input array\")\n",
    "\n",
    "    def transform(self, arr):\n",
    "        og_shape = arr.shape\n",
    "        arr = arr.flatten().reshape(-1, 1)\n",
    "        arr = self.transformer.transform(arr.astype(np.float64))\n",
    "        return arr.reshape(og_shape)\n",
    "\n",
    "survey_search = \"p*\"\n",
    "survey_dir = Path(\"C:/Luke/data/multiscale_TMI/ers_surveys\")\n",
    "tile_dir = Path(\"C:/Luke/data/multiscale_TMI/tiles/\")\n",
    "norm = Norm(\"../utils/AUS_MAGPMAP_v7_ONSHORE_QuantileTransformer.joblib\")\n",
    "scales = sorted([1, 2, 3, 4])\n",
    "\n",
    "def img_to_tiles(\n",
    "    raster_path: Path,\n",
    "    scale: int,\n",
    "    hr_s: int = 240,\n",
    "    norm=False,\n",
    "    nan_val=-999_999,\n",
    "    nan_fill_val: float = None,\n",
    "    valid_mask=None,\n",
    "    out_prefix: str = \"\",\n",
    "    out_ext=\"npy\",\n",
    "    single_output_folder: Path = None,\n",
    "    lcm=12,  # lowest common mutiple of all scales\n",
    "    pad_mode=\"constant\",\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Specify a single raster of scale n, in a group of several scales.\n",
    "    This will tile and save them to numpy arrays or image tiles ready to\n",
    "    load in pytorch.\n",
    "\n",
    "    We assume input raster of any shape, square tiles (h=w), and integer\n",
    "    scale factors.\n",
    "\n",
    "    We include lcm so as to determine a hr image size (multiple of lcm)\n",
    "    that can remain constant for all scales. For example, an lcm of 12\n",
    "    (scales 1,2,3,4) would ensure a hr size[0] of e.g. 110 is padded to\n",
    "    120. The resulting LR sizes for each scale would become 60, 40, and\n",
    "    30. Else, Hr would be padded to e.g. 110, 111, 116, and potentially\n",
    "    have a different tile count each time.\n",
    "    (Or maybe I'm way overthinking it!).\n",
    "    This is repeated but to ensure an integer span of tiles in each dimension.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _pad(t: torch.tensor):\n",
    "        \"\"\"Pad such that each hr/lr pair has an equal number of integer sized tiles\"\"\"\n",
    "        pad_h = t.shape[1] + lcm - (t.shape[1] % lcm)\n",
    "        pad_w = t.shape[2] + lcm - (t.shape[2] % lcm)\n",
    "        pad_h = pad_h + s - (pad_h % s)\n",
    "        pad_w = pad_w + s - (pad_w % s)\n",
    "        pad_h -= t.shape[1]  # .pad() is number of pixels to add...\n",
    "        pad_w -= t.shape[2]  # ... we calculated target total pixels\n",
    "\n",
    "        logging.info(\n",
    "            f\"Padded input: {t.shape[2]}+{pad_w} x {t.shape[1]}+{pad_h} \"\n",
    "            f\"to {t.shape[2] + pad_w} x {t.shape[1] + pad_h} \"\n",
    "        )\n",
    "        return torch.nn.functional.pad(\n",
    "            t, (0, pad_w, 0, pad_h), mode=\"constant\", value=float(\"nan\")\n",
    "        )\n",
    "\n",
    "    def _tile(t: torch.tensor):\n",
    "        \"\"\"Tile 1 raster into many smaller arrays\"\"\"\n",
    "        tpr = t.shape[1] // s  # tiles per row\n",
    "        tpc = t.shape[0] // s  # tiles per column\n",
    "        tiles = t.unfold(0, s, s).unfold(1, s, s)\n",
    "        return tiles.contiguous().view(tpr * tpc, -1, s, s)\n",
    "\n",
    "    def _handle_nans(\n",
    "        tiles: torch.tensor, valid_mask, method=\"remove\", limit: float = 0.0\n",
    "    ):\n",
    "        \"\"\"Remove or replace NaNs in tiles containing more than limit\n",
    "\n",
    "        ML struggles with NaNs. The options are to replace them\n",
    "        with a constant, or to remove any and all tiles with nans\n",
    "        (across all matching tiles across scales).\n",
    "\n",
    "        By default, we replace ALL (limit=0). Code is in place to set a\n",
    "        percentage [0,1] of each tile to consider replacement instead of\n",
    "        removal. This should only be calculated on... the scale with the\n",
    "        most NaN values (as a result of gridding process). You deal with\n",
    "        it if you need to. Check the git history. Maybe it's strictly HR?\n",
    "\n",
    "        We store the valid_mask calculated on the smallest scale (hr)\n",
    "        and reuse it.\n",
    "\n",
    "        \"\"\"\n",
    "        if len(valid_mask) == 0:\n",
    "            valid_mask = (\n",
    "                torch.count_nonzero(\n",
    "                    tiles.isnan(),\n",
    "                    dim=(2, 3),\n",
    "                )\n",
    "                / (tiles.shape[2] * tiles.shape[3])\n",
    "            )\n",
    "            valid_mask = (valid_mask <= limit).to(bool)\n",
    "\n",
    "        tiles = tiles[np.where(valid_mask)]\n",
    "        logger.info(\n",
    "            f\"Dropped {sum(~valid_mask).item()} mostly NaN tiles \"\n",
    "            f\"(> {limit*100}% nan)\"\n",
    "        )\n",
    "\n",
    "        if method == \"replace\":\n",
    "            tiles = torch.nan_to_num(tiles, nan=nan_fill_val)\n",
    "            logger.info(f\"Reverted any NaNs in remaining tiles to {nan_fill_val}\")\n",
    "\n",
    "        return tiles, valid_mask\n",
    "\n",
    "    def _write_files(tiles: np.ndarray):\n",
    "        \"\"\"Save to appropriate directory structure\"\"\"\n",
    "\n",
    "        tile_dir = single_output_folder or raster_path.parent / out_ext\n",
    "        (tile_dir / f\"{scale}-0\").mkdir(parents=True, exist_ok=True)\n",
    "        file_name = f\"{scale}-0/{out_prefix}{raster_path.stem}\"\n",
    "        if \"npy\" in out_ext:\n",
    "            np.save(tile_dir / f\"{file_name}.{out_ext}\", tiles)\n",
    "        elif \"tif\" in out_ext:\n",
    "            for i, tile in enumerate(tiles):\n",
    "                tifffile.imsave(tile_dir / f\"{file_name}_{i}.{out_ext}\", tile)\n",
    "\n",
    "        logger.info(f\"Saved {len(tiles)} tiles to {tile_dir.absolute()}\")\n",
    "\n",
    "    logging.info(f\"Began processing {raster_path}\")\n",
    "\n",
    "    if raster_path.suffix == \".tif\":\n",
    "        raster = tifffile.imread(raster_path)\n",
    "    elif raster_path.suffix == \".ers\":\n",
    "        raster = np.array(rio.open(raster_path).read(1))\n",
    "    raster[raster == nan_val] = float(\"nan\")\n",
    "\n",
    "    t = torch.as_tensor(norm(raster), dtype=torch.float32).unsqueeze(0)\n",
    "    s = hr_s // scale\n",
    "    t = _pad(t).squeeze()\n",
    "    tiles = _tile(t)\n",
    "    tiles, valid_mask = _handle_nans(tiles, valid_mask)\n",
    "    _write_files(tiles.numpy().astype(np.float32))\n",
    "\n",
    "    return valid_mask\n",
    "\n",
    "\n",
    "for survey_path in survey_dir.glob(survey_search):\n",
    "    if not survey_path.is_dir():\n",
    "        continue\n",
    "    \n",
    "    valid_mask = []\n",
    "    for scale in scales:\n",
    "        valid_mask = img_to_tiles(\n",
    "            raster_path=next(survey_path.glob(f\"*{scale:d}.ers\")),\n",
    "            scale=scale,\n",
    "            hr_s=240,\n",
    "            norm=norm.transform,\n",
    "            nan_val=-999_999,\n",
    "            nan_fill_val=float(\"nan\"),\n",
    "            valid_mask=valid_mask,\n",
    "            out_ext=\"tif\",  # output extension\n",
    "            single_output_folder=tile_dir,\n",
    "            lcm=np.lcm.reduce(scales),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ArbSR\n",
    "\n",
    "# ArbSR requires a specific dataset layout (see the matlab version of this script)\n",
    "# ArbSR uses a single HR file and n, m scale downsamplings.\n",
    "# We use a set of pre-gridded files, split into n directories of m scale.\n",
    "# This script organises these directories as per the expectations of ArbSR.\n",
    "# ArbSr uses np.arange(1.5, 4.5, 0.5), we have np.arange(2.0, 5.0, 1.0) == [2,3,4]\n",
    "\n",
    "\n",
    "def process_dir(\n",
    "    tile_dir: Path,\n",
    "    out_dir: Path = None,\n",
    "    val_pct: float = 0.10,  # 10% Val, 85% Train, 5% test\n",
    "    tst_pct: float = 0.05,\n",
    "):\n",
    "    \"\"\"Based on dir name, process as n scale, for scale = \"dir_name_n\" \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(seed=21)\n",
    "    assert tile_dir.exists(), f\"Error, {tile_dir.absolute().as_posix()} not found!\"\n",
    "\n",
    "    def _split_indices():\n",
    "        indices = {}\n",
    "        tot_num = len(list((tile_dir / \"1-0\").iterdir()))\n",
    "        val_num = int(np.round(val_pct * tot_num))  # len(lr_tiles)\n",
    "        tst_num = int(np.round(tst_pct * tot_num))\n",
    "        val_indices = sorted(rng.choice(tot_num, size=val_num, replace=False))\n",
    "        indices[\"test\"] = sorted(rng.choice(tot_num, size=tst_num, replace=False))\n",
    "        # Drop any indices from val if they were also selected in test:\n",
    "        indices[\"val\"] = [i for i in val_indices if i not in indices[\"test\"]]\n",
    "        # Train indices are all remaining indices not in either val or test:\n",
    "        indices[\"train\"] = [\n",
    "            i\n",
    "            for i in range(tot_num)\n",
    "            if (i not in indices[\"val\"] and i not in indices[\"test\"])\n",
    "        ]\n",
    "\n",
    "        logging.info(\n",
    "            f\"{tot_num} tiles, Split: {tot_num-val_num-tst_num}/{val_num}/{tst_num}\"\n",
    "        )\n",
    "        logging.debug(f'\\n{indices[\"train\"]=}\\n{indices[\"val\"]=}\\n{indices[\"test\"]=}')\n",
    "\n",
    "        return indices\n",
    "\n",
    "    def _rearrange_files(scale_dir: Path, indices:dict):\n",
    "        scale = float(scale_dir.stem.replace(\"-\", \".\"))\n",
    "        files = np.array(sorted(list(scale_dir.iterdir())))\n",
    "\n",
    "\n",
    "        for dset in indices.keys(): #train, val, test\n",
    "            out_path = tile_dir / out_dir / dset \n",
    "            if scale == 1:\n",
    "                out_path = out_path / \"HR\"\n",
    "            else:\n",
    "                out_path = out_path / \"LR\" / f\"X{scale:.2f}_X{scale:.2f}\"\n",
    "            out_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            for i, f in enumerate(files[indices[dset]]):\n",
    "                # print(f\"{f} would be renamed to {out_path}\\{i:05d}.tif\")\n",
    "                f.rename(out_path / f\"{i:05d}.tif\")\n",
    "\n",
    "        print(f\"{tile_dir} processed and output to {(out_path).absolute()}\")\n",
    "\n",
    "    indices = _split_indices()\n",
    "    for scale_dir in tile_dir.iterdir():\n",
    "        assert scale_dir.is_dir(), \"Unexpected files found\"\n",
    "        if tile_dir / out_dir == scale_dir:\n",
    "            continue\n",
    "        _rearrange_files(scale_dir, indices)\n",
    "\n",
    "\n",
    "process_dir(tile_dir, out_dir=\"processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So you have line data from a geophysical survey. You've decimated the lines\n",
    "# and gridded it at several specific scale factors, e.g. remove 2nd, 3rd, 4th lines\n",
    "# You now want to turn this survey into individual tiles for ML. So that each tile\n",
    "# covers the same extent, you need to tile them at dimensions relative to their\n",
    "# scale factor. The dimensions are therefore a decimal (or fractional) scale smaller\n",
    "# than the original 1x scale grid.\n",
    "# You may note that 256/3 is not a pleasant number for a discrete count of pixels.\n",
    "# So we use 240, which goes to 120, 80, and 60 pixels per dimension for each of\n",
    "#             1,                 2,  3, and  4 times scale, etc.\n",
    "\n",
    "# An alternative would be to interpolate, but idk how that would affect ArbSR...\n",
    "# Its easier in the image world, because it's just bicubic downsample on the fly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_tiles(data_path, index=0, ext=\"np\", s=256):\n",
    "#     # if \"np\" in ext:\n",
    "#     #     lr_tile = np.load(lr_path)[index][0]\n",
    "#     #     hr_tile = np.load(hr_path)[index][0]\n",
    "#     # elif \"tif\" in ext:\n",
    "#     #     lr_tile = tifffile.imread(f\"{lr_path}\").squeeze()\n",
    "#     #     hr_tile = tifffile.imread(f\"{hr_path}\").squeeze()\n",
    "#     data_path = Path(data_path)\n",
    "\n",
    "#     if \"tif\" in ext:\n",
    "#         lr_tile = tifffile.imread(f\"{next(data_path.glob(f'**/lr/{i}.tif'))}\").squeeze()\n",
    "#         hr_tile = tifffile.imread(f\"{next(data_path.glob(f'**/hr/{i}.tif'))}\").squeeze()\n",
    "\n",
    "#     us = np.array(Image.fromarray(lr_tile).resize((s, s)))\n",
    "\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     plt.subplot(1, 3, 1)\n",
    "#     plt.imshow(us, vmin=hr_tile.min(), vmax=hr_tile.max())\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1, 3, 2)\n",
    "#     plt.imshow(hr_tile)\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1, 3, 3)\n",
    "#     plt.imshow(hr_tile - us, cmap=cc.cm.CET_D7, vmin=-0.5, vmax=0.5)\n",
    "#     plt.colorbar()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2a7693b0d28a18d07a779b8850ec935428aaafb4510b5c22ddb8cee62302900"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('srvey': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
