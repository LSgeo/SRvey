{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert raster to tiled ML-ready data\n",
    "\n",
    "ers and tif files are common for geoscience. We need a quick way to tile these and save them to our standard numpy tile dataset.\n",
    "\n",
    "This notebook defines a function which:\n",
    "1. converts a tif to a pytorch tensor\n",
    "1. pads any nan areas with reflection padding \n",
    "1. unfolds the tensor in each direction (read torch .fold() / .unfold())\n",
    "1. stacks those into a \"batch\" of tiles\n",
    "1. generates a selection of indices for validation and training data\n",
    "1. saves each to a seperate train/val folder\n",
    "1. Generates some QA/QC figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import torch\n",
    "import tifffile\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def img_to_tiles(\n",
    "    lr_raster_path,\n",
    "    hr_raster_path,\n",
    "    lr_out_prefix=\"lr_tiles\",\n",
    "    hr_out_prefix=\"hr_tiles\",\n",
    "    lr_s=32,  # lr tile res\n",
    "    hr_s=128,  # hr tile res\n",
    "    nan_val=-999999,\n",
    "    ext=\"npy\",\n",
    "    norm=False,\n",
    "    single_output_folder=False,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Specify a LR and HR image pair. This will tile and save them to tensor\n",
    "    arrays or image tiles ready to load in pytorch.\n",
    "\n",
    "    Normalisation is hacky and requires further work.\n",
    "\n",
    "    \"\"\"\n",
    "    if norm:\n",
    "        max_ = 213\n",
    "        min_ = -315\n",
    "        mean_ = -38\n",
    "        std_ = 40\n",
    "\n",
    "        # norm = lambda i: (i + 4403.574) / 18454.907 # values from training\n",
    "        # unnorm = lambda i: (i * 18454.907) - 4403.574\n",
    "\n",
    "        norm = lambda i: (i - min_) / (max_ - min_)  # values from training\n",
    "        unnorm = lambda i: (i * (max_ - min_)) + min_\n",
    "    else:\n",
    "        norm = lambda i: i / 8  # NULL OP\n",
    "        print(\"Using temp /8 norm for PPRDC\")\n",
    "        \n",
    "        # norm = lambda i: i  # NULL OP\n",
    "        # unnorm = lambda i: i\n",
    "\n",
    "    if Path(lr_raster_path).suffix == \".tif\":\n",
    "        lr = tifffile.imread(lr_raster_path)\n",
    "        hr = tifffile.imread(hr_raster_path)\n",
    "    elif Path(lr_raster_path).suffix == \".ers\":\n",
    "        lr = np.array(rio.open(lr_raster_path).read(1))\n",
    "        hr = np.array(rio.open(hr_raster_path).read(1))\n",
    "\n",
    "    lr[lr == nan_val] = np.nan\n",
    "    hr[hr == nan_val] = np.nan\n",
    "\n",
    "    lr_tensor = torch.as_tensor(norm(lr), dtype=torch.float32).unsqueeze(0)\n",
    "    hr_tensor = torch.as_tensor(norm(hr), dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    # lr_original_extent = lr_tensor.shape\n",
    "    # hr_original_extent = hr_tensor.shape\n",
    "\n",
    "    # Expand raster size to a common multiple of lr size (which is a multiple of hr)\n",
    "\n",
    "    # padded_w = (lr_tensor.shape[0] + (lr_s - (lr_tensor.shape[0] % lr_s)))\n",
    "    # padded_h = (lr_tensor.shape[1] + (lr_s - (lr_tensor.shape[1] % lr_s)))\n",
    "\n",
    "    lr_tensor = torch.nn.functional.pad(\n",
    "        lr_tensor,\n",
    "        (\n",
    "            0,\n",
    "            (lr_s - (lr_tensor.shape[1] % lr_s)),\n",
    "            0,\n",
    "            (lr_s - (lr_tensor.shape[0] % lr_s)),\n",
    "        ),\n",
    "        mode=\"reflect\",\n",
    "    )\n",
    "    hr_tensor = torch.nn.functional.pad(\n",
    "        hr_tensor,\n",
    "        (\n",
    "            0,\n",
    "            (hr_s - (hr_tensor.shape[1] % hr_s)),\n",
    "            0,\n",
    "            (hr_s - (hr_tensor.shape[0] % hr_s)),\n",
    "        ),\n",
    "        mode=\"reflect\",\n",
    "    )\n",
    "\n",
    "    hr_tensor = hr_tensor[0]\n",
    "    lr_tensor = lr_tensor[0]\n",
    "\n",
    "    # Math to determine and execute the tiling process\n",
    "    lr_tiles_per_row = lr_tensor.shape[1] // lr_s\n",
    "    hr_tiles_per_row = hr_tensor.shape[1] // hr_s\n",
    "    lr_tiles_per_column = lr_tensor.shape[0] // lr_s\n",
    "    hr_tiles_per_column = hr_tensor.shape[0] // hr_s\n",
    "\n",
    "    lr_patches = lr_tensor.unfold(0, lr_s, lr_s).unfold(1, lr_s, lr_s)\n",
    "    hr_patches = hr_tensor.unfold(0, hr_s, hr_s).unfold(1, hr_s, hr_s)\n",
    "\n",
    "    lr_patches = lr_patches.contiguous().view(\n",
    "        lr_tiles_per_row * lr_tiles_per_column, -1, lr_s, lr_s\n",
    "    )\n",
    "    hr_patches = hr_patches.contiguous().view(\n",
    "        hr_tiles_per_row * hr_tiles_per_column, -1, hr_s, hr_s\n",
    "    )\n",
    "\n",
    "    print(f\"{len(lr_patches)=}\")\n",
    "    print(f\"{len(hr_patches)=}\")\n",
    "\n",
    "    print(f\"{lr_patches.shape=}\")\n",
    "    print(f\"{hr_patches.shape=}\")\n",
    "\n",
    "    #  Drop tiles that contain mostly/any nan values, convert rest to some value\n",
    "    allowed_nan_pct = 0.05\n",
    "    valid_mask = (\n",
    "        torch.count_nonzero(lr_patches.isnan(), dim=(2, 3)) / lr_s ** 2\n",
    "    ) <= allowed_nan_pct\n",
    "    lr_patches_masked = lr_patches[valid_mask]\n",
    "    hr_patches_masked = hr_patches[valid_mask]  # HR and LR indices need to match\n",
    "    print(\n",
    "        f\"Dropped {sum(~valid_mask).item()} mostly NaN tiles (> {allowed_nan_pct*100}% nan)\"\n",
    "    )\n",
    "    # nan_val = torch.tensor(0)  # np.nanmean(hr_patches_masked))\n",
    "    # lr_patches_masked[lr_patches_masked == torch.nan] = nan_val\n",
    "    # hr_patches_masked[hr_patches_masked == torch.nan] = nan_val\n",
    "    hr_patches_masked = torch.nan_to_num(hr_patches_masked, nan=0) # nan_val)\n",
    "    lr_patches_masked = torch.nan_to_num(lr_patches_masked, nan=0) # nan_val)\n",
    "    print(f\"Reverted any NaNs in remaining tiles to {nan_val}\")\n",
    "\n",
    "    # Random split the train/val tiles for this dataset\n",
    "    from numpy.random import default_rng\n",
    "\n",
    "    rng = default_rng(seed=21)\n",
    "\n",
    "    val_pct = 0.15  # 15% Val, 85% Train\n",
    "    val_num = int(np.round(val_pct * len(lr_patches_masked)))  # len(lr_patches)\n",
    "    val_indices = sorted(\n",
    "        rng.choice(len(lr_patches_masked), size=val_num, replace=False)\n",
    "    )\n",
    "    print(f\"{val_indices=}\")\n",
    "\n",
    "    train_indices = [i for i in range(len(lr_patches_masked)) if i not in val_indices]\n",
    "    print(f\"{train_indices=}\")\n",
    "    print(\n",
    "        f\"There are {sum(i in train_indices for i in val_indices)} val indices in your train indices :)\"\n",
    "    )\n",
    "\n",
    "    lr_patches_train = lr_patches_masked[train_indices].numpy().astype(np.float32)\n",
    "    hr_patches_train = hr_patches_masked[train_indices].numpy().astype(np.float32)\n",
    "    lr_patches_val = lr_patches_masked[val_indices].numpy().astype(np.float32)\n",
    "    hr_patches_val = hr_patches_masked[val_indices].numpy().astype(np.float32)\n",
    "\n",
    "    print(f\"{len(lr_patches_train)=}\")\n",
    "    print(f\"{len(lr_patches_val)=}\")\n",
    "\n",
    "    print(\"None of these values should show nans!\")\n",
    "    print(f\"{np.min(lr_patches_train)=}\")\n",
    "    print(f\"{np.max(lr_patches_train)=}\")\n",
    "    print(f\"{np.mean(lr_patches_train)=}\")\n",
    "    print(f\"{np.std(lr_patches_train)=}\")\n",
    "    # print(f\"{np.nanmin(hr_patches_train)=}\")\n",
    "    # print(f\"{np.nanmax(hr_patches_train)=}\")\n",
    "\n",
    "    if single_output_folder:\n",
    "        single_output_folder = Path(single_output_folder)\n",
    "        train_dir = single_output_folder / \"train\"\n",
    "        val_dir = single_output_folder / \"val\"\n",
    "    else:\n",
    "        train_dir = Path(hr_raster_path).parent / ext / \"train\"\n",
    "        val_dir = Path(hr_raster_path).parent / ext / \"val\"\n",
    "\n",
    "    (train_dir / \"hr\").mkdir(parents=True, exist_ok=True)\n",
    "    (train_dir / \"lr\").mkdir(parents=True, exist_ok=True)\n",
    "    (val_dir / \"hr\").mkdir(parents=True, exist_ok=True)\n",
    "    (val_dir / \"lr\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    hr_file_name = f\"hr/{Path(hr_raster_path).stem}_hr\"\n",
    "    lr_file_name = f\"lr/{Path(lr_raster_path).stem}_lr\"\n",
    "\n",
    "    if \"npy\" in ext:\n",
    "        np.save(train_dir / f\"{hr_file_name}.{ext}\", hr_patches_train)\n",
    "        np.save(train_dir / f\"{lr_file_name}.{ext}\", lr_patches_train)\n",
    "        np.save(val_dir / f\"{hr_file_name}.{ext}\", hr_patches_val)\n",
    "        np.save(val_dir / f\"{lr_file_name}.{ext}\", lr_patches_val)\n",
    "\n",
    "    if \"tif\" in ext:\n",
    "        for i in range(len(lr_patches_train)):\n",
    "            tifffile.imsave(\n",
    "                train_dir / f\"{hr_file_name}_{i}.{ext}\", hr_patches_train[i]\n",
    "            )\n",
    "            tifffile.imsave(\n",
    "                train_dir / f\"{lr_file_name}_{i}.{ext}\", lr_patches_train[i]\n",
    "            )\n",
    "\n",
    "        for i in range(len(lr_patches_val)):\n",
    "            tifffile.imsave(val_dir / f\"{hr_file_name}_{i}.{ext}\", hr_patches_val[i])\n",
    "            tifffile.imsave(val_dir / f\"{lr_file_name}_{i}.{ext}\", lr_patches_val[i])\n",
    "\n",
    "        print(hr_patches_val[i].shape)\n",
    "        print(lr_patches_val[i].shape)\n",
    "\n",
    "    print(f\"\\nSaved to {val_dir.parent.absolute()}\")\n",
    "\n",
    "    return lr_patches, hr_patches, val_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tiles(data_path, index=0, ext=\"np\", s=256):\n",
    "    # if \"np\" in ext:\n",
    "    #     lr_tile = np.load(lr_path)[index][0]\n",
    "    #     hr_tile = np.load(hr_path)[index][0]\n",
    "    # elif \"tif\" in ext:\n",
    "    #     lr_tile = tifffile.imread(f\"{lr_path}\").squeeze()\n",
    "    #     hr_tile = tifffile.imread(f\"{hr_path}\").squeeze()\n",
    "    data_path = Path(data_path)\n",
    "\n",
    "    if \"tif\" in ext:\n",
    "        lr_tile = tifffile.imread(f\"{next(data_path.glob(f'**/lr/{i}.tif'))}\").squeeze()\n",
    "        hr_tile = tifffile.imread(f\"{next(data_path.glob(f'**/hr/{i}.tif'))}\").squeeze()\n",
    "\n",
    "    us = np.array(Image.fromarray(lr_tile).resize((s, s)))\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(us, vmin=hr_tile.min(), vmax=hr_tile.max())\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(hr_tile)\n",
    "    plt.colorbar()\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(hr_tile - us, cmap=cc.cm.CET_D7, vmin=-0.5, vmax=0.5)\n",
    "    plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey_search = \"*.tif\"\n",
    "survey_search = \"P*\"\n",
    "\n",
    "for survey_path in Path(r\"C:\\Luke\\PhD\\paper2\\SRvey\\utils\\PPDRC\\PPDRC output\").glob(survey_search):\n",
    "    print(survey_path)\n",
    "    root = survey_path\n",
    "\n",
    "    # lr_patches, hr_patches, val_indices = tifs_to_tensors(\n",
    "    #     f\"{root}/{survey_name}_x4_200_LR.tif\",\n",
    "    #     f\"{root}/{survey_name}_x1_50_HR.tif\",\n",
    "    #     ext=\"tif\",\n",
    "    #     norm=True,\n",
    "    # )\n",
    "\n",
    "    lr_patches, hr_patches, val_indices = img_to_tiles(\n",
    "        # hr_raster_path=f\"{root}/{survey_name.name.lower()}_1.ers\",\n",
    "        # lr_raster_path=f\"{root}/{survey_name.name.lower()}_4.ers\",\n",
    "        hr_raster_path=next(survey_path.glob(\"*0200.tif\")),\n",
    "        lr_raster_path=next(survey_path.glob(\"*0050.tif\")),\n",
    "        ext=\"tif\",\n",
    "        norm=False,\n",
    "        single_output_folder=\"C:/Luke/data/Paper 2/PPDRC/lr64\",\n",
    "        nan_val=-999999,\n",
    "        lr_s=64,  # lr tile res\n",
    "        hr_s=256,  # hr tile res\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ers_to_tifs(survey_path, out_dir=\"\"):\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ers_arr = np.array(rio.open(survey_path).read(1))\n",
    "    tifffile.imsave(out_dir / f\"{survey_path.stem}.tif\", ers_arr)\n",
    "    print(f'Saved {Path(out_dir / f\"{survey_path.stem}.tif\").absolute()}')\n",
    "    \n",
    "\n",
    "survey_search = \"*4.ers\"\n",
    "for survey_path in Path(\"C:/Luke/PhD/Oasis Montaj/ArbSR\").glob(survey_search):\n",
    "    print(survey_path)\n",
    "    # survey_path\n",
    "    ers_to_tifs(survey_path, out_dir=\"PPDRC\")\n",
    "\n",
    "# Test no loss of information:\n",
    "# np.max(tifffile.imread(next(Path(r\"C:\\Luke\\PhD\\paper2\\SRvey\\utils\\PPDRC\").glob(\"*.tif\"))) - np.array(rio.open(r\"C:\\Luke\\PhD\\Oasis Montaj\\ArbSR\\p681_1.ers\").read(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in Path(r\"C:\\Luke\\PhD\\paper2\\SRvey\\utils\\PPDRC\\PPDRC output\").glob(\"*.tif\"):\n",
    "    plt.figure()\n",
    "    plt.imshow(tifffile.imread(im))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2a7693b0d28a18d07a779b8850ec935428aaafb4510b5c22ddb8cee62302900"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('srvey': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
