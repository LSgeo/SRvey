{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert raster to tiled ML-ready data\n",
    "\n",
    "ers and tif files are common for geoscience. We need a quick way to tile these and save them to our standard numpy/folder tile dataset.\n",
    "\n",
    "This notebook defines functions which:\n",
    "1. convert an ers/tif to a pytorch tensor\n",
    "1. pads any nan areas with reflection padding \n",
    "1. unfolds the tensor in each direction (read torch .fold() / .unfold())\n",
    "1. stacks those into a \"batch\" of tiles\n",
    "1. generates a selection of indices for validation and training data\n",
    "1. saves each to a seperate train/val folder\n",
    "1. Generates some QA/QC figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2022-04-29 12:04:22,596: ##### Starting new log\n",
      "INFO:2022-04-29 12:04:22,599: Using ../utils/AUS_MAGPMAP_v7_ONSHORE_QuantileTransformer.joblib to transform your input array\n",
      "INFO:2022-04-29 12:04:22,602: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p1505\\p1505_1.ers\n",
      "INFO:2022-04-29 12:04:23,663: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:24,431: Tiles min/max/mean: 0.00/2.64/0.59\n",
      "INFO:2022-04-29 12:04:24,432: Saved 405 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:24,444: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p1505\\p1505_2.ers\n",
      "INFO:2022-04-29 12:04:24,789: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:25,457: Tiles min/max/mean: 0.00/2.64/0.60\n",
      "INFO:2022-04-29 12:04:25,458: Saved 405 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:25,463: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p1505\\p1505_3.ers\n",
      "INFO:2022-04-29 12:04:25,645: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:26,563: Tiles min/max/mean: 0.00/2.64/0.61\n",
      "INFO:2022-04-29 12:04:26,564: Saved 420 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:26,566: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p1505\\p1505_4.ers\n",
      "INFO:2022-04-29 12:04:26,711: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:27,658: Tiles min/max/mean: 0.00/2.63/0.60\n",
      "INFO:2022-04-29 12:04:27,659: Saved 420 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:27,662: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p578\\p578_1.ers\n",
      "INFO:2022-04-29 12:04:29,146: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:29,998: Tiles min/max/mean: -3.13/3.10/-0.04\n",
      "INFO:2022-04-29 12:04:29,999: Saved 396 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:30,011: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p578\\p578_2.ers\n",
      "INFO:2022-04-29 12:04:30,431: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:31,285: Tiles min/max/mean: -3.13/3.10/-0.04\n",
      "INFO:2022-04-29 12:04:31,286: Saved 396 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:31,292: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p578\\p578_3.ers\n",
      "INFO:2022-04-29 12:04:31,535: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:32,412: Tiles min/max/mean: -3.10/2.99/-0.03\n",
      "INFO:2022-04-29 12:04:32,412: Saved 414 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:32,415: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p578\\p578_4.ers\n",
      "INFO:2022-04-29 12:04:32,563: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:33,349: Tiles min/max/mean: -2.94/2.96/-0.03\n",
      "INFO:2022-04-29 12:04:33,350: Saved 396 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:33,353: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p681\\p681_1.ers\n",
      "INFO:2022-04-29 12:04:34,548: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:35,342: Tiles min/max/mean: -2.81/3.11/0.15\n",
      "INFO:2022-04-29 12:04:35,343: Saved 396 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:35,354: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p681\\p681_2.ers\n",
      "INFO:2022-04-29 12:04:35,717: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:36,475: Tiles min/max/mean: -2.65/3.11/0.15\n",
      "INFO:2022-04-29 12:04:36,476: Saved 396 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:36,481: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p681\\p681_3.ers\n",
      "INFO:2022-04-29 12:04:36,683: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:37,614: Tiles min/max/mean: -2.47/3.09/0.16\n",
      "INFO:2022-04-29 12:04:37,615: Saved 396 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:37,618: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p681\\p681_4.ers\n",
      "INFO:2022-04-29 12:04:37,776: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:38,712: Tiles min/max/mean: -2.47/3.03/0.16\n",
      "INFO:2022-04-29 12:04:38,712: Saved 396 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:38,715: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p733\\p733_1.ers\n",
      "INFO:2022-04-29 12:04:40,251: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:41,373: Tiles min/max/mean: -2.66/2.80/0.28\n",
      "INFO:2022-04-29 12:04:41,374: Saved 506 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:41,388: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p733\\p733_2.ers\n",
      "INFO:2022-04-29 12:04:41,810: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:42,996: Tiles min/max/mean: -2.63/2.77/0.28\n",
      "INFO:2022-04-29 12:04:42,998: Saved 506 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:43,012: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p733\\p733_3.ers\n",
      "INFO:2022-04-29 12:04:43,284: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:44,484: Tiles min/max/mean: -2.63/2.77/0.28\n",
      "INFO:2022-04-29 12:04:44,485: Saved 529 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:44,489: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p733\\p733_4.ers\n",
      "INFO:2022-04-29 12:04:44,662: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:45,574: Tiles min/max/mean: -2.53/2.78/0.28\n",
      "INFO:2022-04-29 12:04:45,574: Saved 506 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:45,576: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p735\\p735_1.ers\n",
      "INFO:2022-04-29 12:04:47,667: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:49,242: Tiles min/max/mean: -3.12/3.17/0.56\n",
      "INFO:2022-04-29 12:04:49,243: Saved 770 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:49,264: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p735\\p735_2.ers\n",
      "INFO:2022-04-29 12:04:49,947: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:51,720: Tiles min/max/mean: -3.11/3.16/0.56\n",
      "INFO:2022-04-29 12:04:51,721: Saved 770 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:51,728: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p735\\p735_3.ers\n",
      "INFO:2022-04-29 12:04:52,094: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:53,527: Tiles min/max/mean: -3.11/3.12/0.54\n",
      "INFO:2022-04-29 12:04:53,527: Saved 828 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:53,531: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p735\\p735_4.ers\n",
      "INFO:2022-04-29 12:04:53,759: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:55,306: Tiles min/max/mean: -3.10/3.15/0.53\n",
      "INFO:2022-04-29 12:04:55,307: Saved 805 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:55,310: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p738\\p738_1.ers\n",
      "INFO:2022-04-29 12:04:56,624: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:57,658: Tiles min/max/mean: -2.06/2.24/0.28\n",
      "INFO:2022-04-29 12:04:57,659: Saved 455 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:57,672: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p738\\p738_2.ers\n",
      "INFO:2022-04-29 12:04:58,080: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:04:58,969: Tiles min/max/mean: -1.84/1.74/0.28\n",
      "INFO:2022-04-29 12:04:58,969: Saved 455 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:04:58,975: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p738\\p738_3.ers\n",
      "INFO:2022-04-29 12:04:59,199: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:00,100: Tiles min/max/mean: -1.67/1.83/0.28\n",
      "INFO:2022-04-29 12:05:00,100: Saved 468 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:00,104: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p738\\p738_4.ers\n",
      "INFO:2022-04-29 12:05:00,260: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:01,180: Tiles min/max/mean: -1.79/1.50/0.28\n",
      "INFO:2022-04-29 12:05:01,181: Saved 455 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:01,183: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p739\\P739_1.ers\n",
      "INFO:2022-04-29 12:05:01,730: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:02,090: Tiles min/max/mean: -1.84/2.44/0.45\n",
      "INFO:2022-04-29 12:05:02,090: Saved 195 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:02,096: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p739\\P739_2.ers\n",
      "INFO:2022-04-29 12:05:02,250: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:02,593: Tiles min/max/mean: -1.74/2.36/0.45\n",
      "INFO:2022-04-29 12:05:02,594: Saved 195 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:02,596: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p739\\P739_3.ers\n",
      "INFO:2022-04-29 12:05:02,710: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:03,299: Tiles min/max/mean: -1.66/2.18/0.44\n",
      "INFO:2022-04-29 12:05:03,299: Saved 210 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:03,302: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p739\\P739_4.ers\n",
      "INFO:2022-04-29 12:05:03,406: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:03,861: Tiles min/max/mean: -1.61/2.33/0.44\n",
      "INFO:2022-04-29 12:05:03,862: Saved 210 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:03,864: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p742\\p742_1.ers\n",
      "INFO:2022-04-29 12:05:04,256: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:04,514: Tiles min/max/mean: -1.27/1.52/0.14\n",
      "INFO:2022-04-29 12:05:04,514: Saved 112 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:04,519: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p742\\p742_2.ers\n",
      "INFO:2022-04-29 12:05:04,657: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:04,889: Tiles min/max/mean: -1.26/1.49/0.14\n",
      "INFO:2022-04-29 12:05:04,890: Saved 112 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:04,893: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p742\\p742_3.ers\n",
      "INFO:2022-04-29 12:05:05,008: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:05,247: Tiles min/max/mean: -1.25/1.39/0.15\n",
      "INFO:2022-04-29 12:05:05,248: Saved 112 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:05,250: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p742\\p742_4.ers\n",
      "INFO:2022-04-29 12:05:05,335: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:05,621: Tiles min/max/mean: -1.27/1.28/0.15\n",
      "INFO:2022-04-29 12:05:05,622: Saved 112 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:05,624: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p756\\p756_1.ers\n",
      "INFO:2022-04-29 12:05:06,296: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:06,824: Tiles min/max/mean: -2.18/2.69/0.20\n",
      "INFO:2022-04-29 12:05:06,824: Saved 234 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:06,832: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p756\\p756_2.ers\n",
      "INFO:2022-04-29 12:05:07,063: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:07,545: Tiles min/max/mean: -2.08/2.68/0.20\n",
      "INFO:2022-04-29 12:05:07,546: Saved 234 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:07,549: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p756\\p756_3.ers\n",
      "INFO:2022-04-29 12:05:07,688: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:08,327: Tiles min/max/mean: -2.13/2.53/0.20\n",
      "INFO:2022-04-29 12:05:08,328: Saved 252 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:08,330: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p756\\p756_4.ers\n",
      "INFO:2022-04-29 12:05:08,448: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:08,945: Tiles min/max/mean: -2.02/2.52/0.19\n",
      "INFO:2022-04-29 12:05:08,946: Saved 252 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:08,948: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p758\\p758_1.ers\n",
      "INFO:2022-04-29 12:05:09,671: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:10,192: Tiles min/max/mean: -3.25/3.10/0.32\n",
      "INFO:2022-04-29 12:05:10,193: Saved 240 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:10,200: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p758\\p758_2.ers\n",
      "INFO:2022-04-29 12:05:10,442: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:11,022: Tiles min/max/mean: -3.23/3.10/0.33\n",
      "INFO:2022-04-29 12:05:11,023: Saved 240 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:11,026: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p758\\p758_3.ers\n",
      "INFO:2022-04-29 12:05:11,184: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:11,660: Tiles min/max/mean: -3.21/3.09/0.33\n",
      "INFO:2022-04-29 12:05:11,661: Saved 252 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n",
      "INFO:2022-04-29 12:05:11,663: Began processing C:\\Luke\\data\\multiscale_TMI\\ers_surveys\\p758\\p758_4.ers\n",
      "INFO:2022-04-29 12:05:11,770: Changed NaNs in some tiles to 0\n",
      "INFO:2022-04-29 12:05:12,252: Tiles min/max/mean: -3.16/2.93/0.34\n",
      "INFO:2022-04-29 12:05:12,254: Saved 240 tiles to C:\\Luke\\data\\multiscale_TMI\\tiles\n"
     ]
    }
   ],
   "source": [
    "# Initialise the valid mask dictionary in a cell above this one... so we can rerun the cell below.\n",
    "# valid_d = None\n",
    "\n",
    "import logging\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import torch\n",
    "import tifffile\n",
    "from PIL import Image\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(levelname)s:%(asctime)s: %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"##### Starting new log\")\n",
    "\n",
    "\n",
    "class Norm:\n",
    "    def __init__(self, t_file_path):\n",
    "        \"\"\"Load a pre-fit sklearn Transformer to normalise input array\"\"\"\n",
    "\n",
    "        self.transformer = joblib.load(t_file_path)\n",
    "        logger.info(f\"Using {t_file_path} to transform your input array\")\n",
    "\n",
    "    def transform(self, arr):\n",
    "        og_shape = arr.shape\n",
    "        arr = arr.flatten().reshape(-1, 1)\n",
    "        arr = self.transformer.transform(arr.astype(np.float64))\n",
    "        return arr.reshape(og_shape)\n",
    "\n",
    "\n",
    "survey_search = \"p*\"\n",
    "survey_dir = Path(\"C:/Luke/data/multiscale_TMI/ers_surveys\")\n",
    "tile_dir = Path(\"C:/Luke/data/multiscale_TMI/tiles/\")\n",
    "norm = Norm(\"../utils/AUS_MAGPMAP_v7_ONSHORE_QuantileTransformer.joblib\")\n",
    "scales = sorted([1, 2, 3, 4])\n",
    "\n",
    "\n",
    "def img_to_tiles(\n",
    "    raster_path: Path,\n",
    "    scale: int,\n",
    "    hr_s: int = 240,\n",
    "    norm=False,\n",
    "    nan_val=-999_999,\n",
    "    nan_fill_val: float = None,\n",
    "    valid_mask=None,\n",
    "    out_prefix: str = \"\",\n",
    "    out_ext=\"npy\",\n",
    "    single_output_folder: Path = None,\n",
    "    lcm=12,  # lowest common mutiple of all scales\n",
    "    pad_mode=\"constant\",\n",
    "    method=\"replace\",\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Specify a single raster of scale n, in a group of several scales.\n",
    "    This will tile and save them to numpy arrays or image tiles ready to\n",
    "    load in pytorch.\n",
    "\n",
    "    We assume input raster of any shape, square tiles (h=w), and integer\n",
    "    scale factors.\n",
    "\n",
    "    We include lcm so as to determine a hr image size (multiple of lcm)\n",
    "    that can remain constant for all scales. For example, an lcm of 12\n",
    "    (scales 1,2,3,4) would ensure a hr size[0] of e.g. 110 is padded to\n",
    "    120. The resulting LR sizes for each scale would become 60, 40, and\n",
    "    30. Else, Hr would be padded to e.g. 110, 111, 116, and potentially\n",
    "    have a different tile count each time.\n",
    "    (Or maybe I'm way overthinking it!).\n",
    "    This is repeated but to ensure an integer span of tiles in each dimension.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _pad(t: torch.tensor):\n",
    "        \"\"\"Pad such that each hr/lr pair has an equal number of integer sized tiles\"\"\"\n",
    "        pad_h = t.shape[1] + lcm - (t.shape[1] % lcm)\n",
    "        pad_w = t.shape[2] + lcm - (t.shape[2] % lcm)\n",
    "        pad_h = pad_h + s - (pad_h % s)\n",
    "        pad_w = pad_w + s - (pad_w % s)\n",
    "        pad_h -= t.shape[1]  # .pad() is number of pixels to add...\n",
    "        pad_w -= t.shape[2]  # ... we calculated target total pixels\n",
    "\n",
    "        logging.debug(\n",
    "            f\"Padded input: {t.shape[2]}+{pad_w} x {t.shape[1]}+{pad_h} \"\n",
    "            f\"to {t.shape[2] + pad_w} x {t.shape[1] + pad_h} \"\n",
    "        )\n",
    "        return torch.nn.functional.pad(\n",
    "            t, (0, pad_w, 0, pad_h), mode=\"constant\", value=float(\"nan\")\n",
    "        )\n",
    "\n",
    "    def _tile(t: torch.tensor):\n",
    "        \"\"\"Tile 1 raster into many smaller arrays\"\"\"\n",
    "        tpr = t.shape[1] // s  # tiles per row\n",
    "        tpc = t.shape[0] // s  # tiles per column\n",
    "        tiles = t.unfold(0, s, s).unfold(1, s, s)\n",
    "        return tiles.contiguous().view(tpr * tpc, -1, s, s)\n",
    "\n",
    "    def _handle_nans(\n",
    "        tiles: torch.tensor,\n",
    "        valid_mask: np.ndarray = None,\n",
    "        method=\"remove\",\n",
    "        limit: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"Remove or replace NaNs in tiles containing more than limit\n",
    "\n",
    "        ML struggles with NaNs. The options are to replace them\n",
    "        with a constant, or to remove any and all tiles with nans\n",
    "        (across all matching tiles across scales).\n",
    "\n",
    "        By default, we replace ALL (limit=0). Code is in place to set a\n",
    "        percentage [0,1] of each tile to consider replacement instead of\n",
    "        removal. This should only be calculated on... the scale with the\n",
    "        most NaN values (as a result of gridding process). You deal with\n",
    "        it if you need to. Check the git history. Maybe it's strictly HR?\n",
    "        Pro-tip, it aint #TODO #YOLO. Calculate a mask on each scale and collate.\n",
    "\n",
    "        We store the valid_mask calculated on the smallest scale (hr)\n",
    "        and reuse it. #TODO calculate valid mask on all scales and do an\n",
    "        element-wise OR op, THEN use the mask on all scales.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        if method == \"replace\":\n",
    "            tiles = torch.nan_to_num(tiles, nan=nan_fill_val).numpy()\n",
    "            logger.info(\n",
    "                f\"Changed NaNs in {'some'} tiles to {nan_fill_val}\"\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            ### Each scale may have a slightly different valid_mask. We want to ensure\n",
    "            # We drop all invalid (nan) values in tiles, common between all scales.\n",
    "            # So we calculate a logical_or on this scales mask, and the previous valid\n",
    "            # mask result (which should slowly accumulate all invalid tiles)\n",
    "            # # Calculate percentage of each tile that is NaN valued & threshold\n",
    "            # new_valid_mask = torch.count_nonzero(tiles.isnan(), dim=(2, 3)) / (\n",
    "            #     tiles.shape[2] * tiles.shape[3]\n",
    "            # )\n",
    "            # new_valid_mask = (new_valid_mask <= limit).to(bool)\n",
    "\n",
    "            # if len(valid_mask) == 0: # When we are processing this survey for the first time\n",
    "            #     valid_mask = np.zeros_like(new_valid_mask).astype(bool)\n",
    "\n",
    "            # new_valid_mask = np.logical_or(valid_mask, new_valid_mask)\n",
    "            # tiles = tiles[np.where(new_valid_mask)]\n",
    "            # logger.info(\n",
    "            #     f\"Dropped {sum(~new_valid_mask)} mostly NaN tiles (> {limit*100}% nan)\"\n",
    "            # )\n",
    "\n",
    "        return tiles #, new_valid_mask\n",
    "\n",
    "    def _write_files(tiles: np.ndarray):\n",
    "        \"\"\"Save to appropriate directory structure\"\"\"\n",
    "\n",
    "        tile_dir = single_output_folder or raster_path.parent / out_ext\n",
    "        file_name = f\"{scale}-0/{out_prefix}{raster_path.stem}\"\n",
    "\n",
    "        if np.isnan(tiles).any() or np.isinf(tiles).any():\n",
    "            bad = []\n",
    "            for i, tile in enumerate(tiles):\n",
    "                if np.isnan(tile).any():\n",
    "                    bad.append([file_name, i])\n",
    "            print(f\"Your data {bad} contained NaN valued cells.\")\n",
    "\n",
    "        (tile_dir / f\"{scale}-0\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if \"npy\" in out_ext:\n",
    "            np.save(tile_dir / f\"{file_name}.{out_ext}\", tiles)\n",
    "        elif \"tif\" in out_ext:\n",
    "            for i, tile in enumerate(tiles):\n",
    "                tifffile.imsave(tile_dir / f\"{file_name}_{i}.{out_ext}\", tile)\n",
    "        logger.info(\n",
    "            f\"Tiles min/max/mean: {tiles.min():0.2f}/{tiles.max():0.2f}/{tiles.mean():0.2f}\"\n",
    "        )\n",
    "        logger.info(f\"Saved {len(tiles)} tiles to {tile_dir.absolute()}\")\n",
    "\n",
    "    logging.info(f\"Began processing {raster_path}\")\n",
    "\n",
    "    if raster_path.suffix == \".tif\":\n",
    "        raster = tifffile.imread(raster_path)\n",
    "    elif raster_path.suffix == \".ers\":\n",
    "        raster = np.array(rio.open(raster_path).read(1))\n",
    "    raster[raster == nan_val] = float(\"nan\")\n",
    "\n",
    "    t = torch.as_tensor(norm(raster), dtype=torch.float32).unsqueeze(0)\n",
    "    s = hr_s // scale\n",
    "    t = _pad(t).squeeze()\n",
    "    tiles = _tile(t)\n",
    "    tiles = _handle_nans(tiles, valid_mask, method=method) # tiles, new_valid_mask\n",
    "    _write_files(tiles.astype(np.float32))\n",
    "\n",
    "    return None #new_valid_mask\n",
    "\n",
    "\n",
    "# if valid_d == None:\n",
    "#     valid_d = {}  # Store the calculated valid mask for each survey\n",
    "\n",
    "for survey_path in survey_dir.glob(survey_search):\n",
    "    if not survey_path.is_dir():\n",
    "        continue\n",
    "\n",
    "    # if valid_d.get(survey_path.name) == None:\n",
    "    #     valid_d[survey_path.name] = []\n",
    "\n",
    "    for i, scale in enumerate(scales):\n",
    "        img_to_tiles( # new_valid_mask =\n",
    "            raster_path=next(survey_path.glob(f\"*{scale:d}.ers\")),\n",
    "            scale=scale,\n",
    "            hr_s=128,\n",
    "            norm=norm.transform,\n",
    "            nan_val=-999_999,\n",
    "            nan_fill_val=0,\n",
    "            # valid_mask=valid_d[survey_path.name],\n",
    "            out_ext=\"tif\",  # output extension\n",
    "            single_output_folder=tile_dir,\n",
    "            lcm=np.lcm.reduce(scales),\n",
    "            method=\"replace\",\n",
    "        )\n",
    "\n",
    "        # if sum(new_valid_mask) > sum(valid_d[survey_path.name]):\n",
    "        #     valid_d[survey_path.name] = new_valid_mask\n",
    "        #     logger.critical(f\"Calculated a new valid mask! Rerun this cell\")\n",
    "\n",
    "    # valid_d[survey_path.name] = new_valid_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ArbSR\n",
    "\n",
    "# ArbSR requires a specific dataset layout (see the matlab version of this script)\n",
    "# ArbSR uses a single HR file and n, m scale downsamplings.\n",
    "# We use a set of pre-gridded files, split into n directories of m scale.\n",
    "# This script organises these directories as per the expectations of ArbSR.\n",
    "# ArbSr uses np.arange(1.5, 4.5, 0.5), we have np.arange(2.0, 5.0, 1.0) == [2,3,4]\n",
    "\n",
    "\n",
    "def process_dir(\n",
    "    tile_dir: Path,\n",
    "    out_dir: Path = None,\n",
    "    val_pct: float = 0.10,  # 10% Val, 85% Train, 5% test\n",
    "    tst_pct: float = 0.05,\n",
    "):\n",
    "    \"\"\"Based on dir name, process as n scale, for scale = \"dir_name_n\" \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(seed=21)\n",
    "    assert tile_dir.exists(), f\"Error, {tile_dir.absolute().as_posix()} not found!\"\n",
    "\n",
    "    def _split_indices():\n",
    "        indices = {}\n",
    "        tot_num = len(list((tile_dir / \"1-0\").iterdir()))\n",
    "        val_num = int(np.round(val_pct * tot_num))  # len(lr_tiles)\n",
    "        tst_num = int(np.round(tst_pct * tot_num))\n",
    "        val_indices = sorted(rng.choice(tot_num, size=val_num, replace=False))\n",
    "        indices[\"test\"] = sorted(rng.choice(tot_num, size=tst_num, replace=False))\n",
    "        # Drop any indices from val if they were also selected in test:\n",
    "        indices[\"val\"] = [i for i in val_indices if i not in indices[\"test\"]]\n",
    "        # Train indices are all remaining indices not in either val or test:\n",
    "        indices[\"train\"] = [\n",
    "            i\n",
    "            for i in range(tot_num)\n",
    "            if (i not in indices[\"val\"] and i not in indices[\"test\"])\n",
    "        ]\n",
    "\n",
    "        logging.info(\n",
    "            f\"{tot_num} tiles, Split: {tot_num-val_num-tst_num}/{val_num}/{tst_num}\"\n",
    "        )\n",
    "        logging.debug(f'\\n{indices[\"train\"]=}\\n{indices[\"val\"]=}\\n{indices[\"test\"]=}')\n",
    "\n",
    "        return indices\n",
    "\n",
    "    def _rearrange_files(scale_dir: Path, indices: dict):\n",
    "        scale = float(scale_dir.stem.replace(\"-\", \".\"))\n",
    "        files = np.array(sorted(list(scale_dir.iterdir())))\n",
    "\n",
    "        for dset in indices.keys():  # train, val, test\n",
    "            out_path = tile_dir / out_dir / dset\n",
    "            if scale == 1:\n",
    "                out_path = out_path / \"HR\"\n",
    "            else:\n",
    "                out_path = out_path / \"LR\" / f\"X{scale:.2f}_X{scale:.2f}\"\n",
    "            out_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            for i, f in enumerate(files[indices[dset]]):\n",
    "                # print(f\"{f} would be renamed to {out_path}\\{i:05d}.tif\")\n",
    "                f.rename(out_path / f\"{i:05d}.tif\")\n",
    "\n",
    "        print(f\"{tile_dir / out_dir} processed and output to {(out_path).absolute()}\")\n",
    "\n",
    "    indices = _split_indices()\n",
    "    for scale_dir in tile_dir.iterdir():\n",
    "        # print(scale_dir.absolute())\n",
    "        assert scale_dir.is_dir(), \"Unexpected files found\"\n",
    "        if tile_dir / out_dir == scale_dir:\n",
    "            continue\n",
    "        if \"old_\" in scale_dir.name:\n",
    "            continue\n",
    "        _rearrange_files(scale_dir, indices)\n",
    "\n",
    "\n",
    "process_dir(tile_dir, out_dir=\"processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So you have line data from a geophysical survey. You've decimated the lines\n",
    "# and gridded it at several specific scale factors, e.g. remove 2nd, 3rd, 4th lines\n",
    "# You now want to turn this survey into individual tiles for ML. So that each tile\n",
    "# covers the same extent, you need to tile them at dimensions relative to their\n",
    "# scale factor. The dimensions are therefore a decimal (or fractional) scale smaller\n",
    "# than the original 1x scale grid.\n",
    "# You may note that 256/3 is not a pleasant number for a discrete count of pixels.\n",
    "# So we use 240, which goes to 120, 80, and 60 pixels per dimension for each of\n",
    "#             1,                 2,  3, and  4 times scale, etc.\n",
    "\n",
    "# An alternative would be to interpolate, but idk how that would affect ArbSR...\n",
    "# Its easier in the image world, because it's just bicubic downsample on the fly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_tiles(data_path, index=0, ext=\"np\", s=256):\n",
    "#     # if \"np\" in ext:\n",
    "#     #     lr_tile = np.load(lr_path)[index][0]\n",
    "#     #     hr_tile = np.load(hr_path)[index][0]\n",
    "#     # elif \"tif\" in ext:\n",
    "#     #     lr_tile = tifffile.imread(f\"{lr_path}\").squeeze()\n",
    "#     #     hr_tile = tifffile.imread(f\"{hr_path}\").squeeze()\n",
    "#     data_path = Path(data_path)\n",
    "\n",
    "#     if \"tif\" in ext:\n",
    "#         lr_tile = tifffile.imread(f\"{next(data_path.glob(f'**/lr/{i}.tif'))}\").squeeze()\n",
    "#         hr_tile = tifffile.imread(f\"{next(data_path.glob(f'**/hr/{i}.tif'))}\").squeeze()\n",
    "\n",
    "#     us = np.array(Image.fromarray(lr_tile).resize((s, s)))\n",
    "\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     plt.subplot(1, 3, 1)\n",
    "#     plt.imshow(us, vmin=hr_tile.min(), vmax=hr_tile.max())\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1, 3, 2)\n",
    "#     plt.imshow(hr_tile)\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1, 3, 3)\n",
    "#     plt.imshow(hr_tile - us, cmap=cc.cm.CET_D7, vmin=-0.5, vmax=0.5)\n",
    "#     plt.colorbar()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2a7693b0d28a18d07a779b8850ec935428aaafb4510b5c22ddb8cee62302900"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('srvey': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
