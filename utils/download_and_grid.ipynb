{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and grid gravity point data\n",
    "We follow Geoscience Australia's geophys_utils package examples to query the netcdf database of gravity point data.\n",
    "\n",
    "If this is the first time running this in your venv, clone and install [geophys_utils](https://github.com/GeoscienceAustralia/geophys_utils) using `pip install -e path\\to\\geophys_utils`\n",
    "\n",
    "You may also need to hack in the examples code, e.g. by `%cd geophys_utils\\examples`\n",
    "\n",
    "## Semi-automatic gridding\n",
    "Luke Smith\n",
    "\n",
    "We want to:\n",
    "1. Query GA for point and line data over an extent with decent gravity coverage.\n",
    "1. Compile the netCDF files available - i.e., identify each survey\n",
    "1. Plot the point data and colour by value/survey/etc\n",
    "1. Grid the data - at different cell sizes.\n",
    "\n",
    "\n",
    "Check out [Fatiando's notebook](https://nbviewer.org/github/fatiando/data/blob/main/osborne-magnetic/prepare.ipynb) for a fantastic resource!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import colorcet as cc\n",
    "import harmonica as hm\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import pooch\n",
    "import pygmt\n",
    "import pyproj\n",
    "import verde as vd\n",
    "import xarray as xr\n",
    "from pyproj import Transformer\n",
    "from pyproj.aoi import AreaOfInterest\n",
    "from pyproj.database import query_utm_crs_info\n",
    "\n",
    "from geophys_utils import NetCDFPointUtils, CSWUtils\n",
    "from geophys_utils import get_spatial_ref_from_wkt, get_utm_wkt, transform_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From CSW data discovery example 1\n",
    "cswu = CSWUtils(\"https://ecat.ga.gov.au/geonetwork/srv/eng/csw\")\n",
    "\n",
    "## grav\n",
    "# theme = \"Gravity\"\n",
    "# keywords = \"point, gravity, point located data, ground digital data, geophysical survey\"  # Comma-separated list of keywords\n",
    "# GDA94_bounds = (141.0, -32.2, 141.6, -31.7) # Broken Hill, NSW\n",
    "\n",
    "## mag\n",
    "theme = \"Magnetics\"\n",
    "keywords = \"AWAGS, Line, Magnetic, Magnetics, airborne digital data, geophysical survey\"\n",
    "gda94_bounds = (144.01, -36.01, 147.05, -34.01) #ESWN\n",
    "region = (144.01, 147.05, -36.01, -34.01) #WESN\n",
    "# Hay, Narrandera, Deniliquin, Jerilderie, NSW\n",
    "\n",
    "record_generator = cswu.query_csw(\n",
    "    keyword_list=keywords,\n",
    "    # anytext_list=allwords,\n",
    "    # titleword_list=titlewords,\n",
    "    bounding_box=gda94_bounds,\n",
    "    # start_datetime=start_date,\n",
    "    # stop_datetime=end_date,\n",
    "    # max_total_records=2000\n",
    ")\n",
    "\n",
    "nc_paths = [\n",
    "    distribution[\"url\"] for distribution in cswu.get_netcdf_urls(record_generator)\n",
    "]\n",
    "\n",
    "registry = {Path(nc_path).name: None for nc_path in nc_paths}\n",
    "urls = {\n",
    "    Path(nc_path).name: \"https://dapds00.nci.org.au/thredds/fileServer/\" + nc_path[41:]\n",
    "    for nc_path in nc_paths\n",
    "}\n",
    "print(f\"Found {len(nc_paths)} matching netCDFs\")\n",
    "\n",
    "doggo = pooch.create(\n",
    "    path=f\"C:/Luke/data/pooch/{theme}\",\n",
    "    base_url=\"\",\n",
    "    registry=registry,\n",
    "    urls=urls,\n",
    ")\n",
    "\n",
    "files = [doggo.fetch(stick) for stick in doggo.registry_files]\n",
    "print(f\"Fetched {len(files)} files, woof!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From geophys_utils \"new\" Example 9\n",
    "# Create NetCDFPointUtils object for specified netCDF dataset\n",
    "\n",
    "\n",
    "def rescale_array(input_np_array, new_range_min=0, new_range_max=1):\n",
    "    old_min = input_np_array.min()\n",
    "    old_range = input_np_array.max() - old_min\n",
    "    new_range = new_range_max - new_range_min\n",
    "\n",
    "    return ((input_np_array - old_min) / old_range * new_range) + new_range_min\n",
    "\n",
    "\n",
    "def plot_survey_points(\n",
    "    netcdf_path, variable_to_map, colour_scheme=\"cet_CET_L16\", fillval_fix=False\n",
    "):\n",
    "\n",
    "    nc = netCDF4.Dataset(str(netcdf_path) + (\"#fillmismatch\" if fillval_fix else \"\"))\n",
    "    npu = NetCDFPointUtils(nc)\n",
    "    print(npu.xycoords[:])\n",
    "\n",
    "    utm_wkt, utm_coords = npu.utm_coords(npu.xycoords[:])\n",
    "    utm_zone = get_spatial_ref_from_wkt(utm_wkt).GetUTMZone()\n",
    "    southern_hemisphere = utm_zone < 0  # True if Southern Hemisphere\n",
    "    utm_zone = abs(utm_zone)\n",
    "    projection = ccrs.UTM(zone=utm_zone, southern_hemisphere=southern_hemisphere)\n",
    "\n",
    "    # print(nc.variables)\n",
    "    variable = nc.variables[variable_to_map][:]\n",
    "    colour_array = rescale_array(variable, 0, 1)\n",
    "\n",
    "    # map_image = cimgt.OSM()# http://developer.mapquest.com/web/products/open/map for terms of use\n",
    "    # map_image = cimgt.StamenTerrain() # http://maps.stamen.com/\n",
    "    map_image = cimgt.QuadtreeTiles(desired_tile_form=\"RGB\")  # PIL image mode\n",
    "    fig = plt.figure(figsize=(30, 20))\n",
    "\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=projection)\n",
    "    ax.set_title(f\"Point {theme} Survey - {nc.getncattr('title')}\")\n",
    "    ax.add_image(map_image, 10)\n",
    "\n",
    "    # set the x and y axis tick values\n",
    "    x_min = np.min(utm_coords[:, 0])\n",
    "    x_max = np.max(utm_coords[:, 0])\n",
    "    y_min = np.min(utm_coords[:, 1])\n",
    "    y_max = np.max(utm_coords[:, 1])\n",
    "\n",
    "    range_x = x_max - x_min\n",
    "    range_y = y_max - y_min\n",
    "    ax.set_xticks([x_min, range_x / 2 + x_min, x_max])\n",
    "    ax.set_yticks([y_min, range_y / 2 + y_min, y_max])\n",
    "\n",
    "    # set the x and y axis labels\n",
    "    ax.set_xlabel(\"Eastings (m)\", rotation=0, labelpad=20)\n",
    "    ax.set_ylabel(\"Northings (m)\", rotation=90, labelpad=20)\n",
    "\n",
    "    # See link for possible colourmap schemes: https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "    cm = plt.cm.get_cmap(colour_scheme)\n",
    "\n",
    "    # build a scatter plot of the specified data, define marker, spatial reference system, and the chosen colour map type\n",
    "    sc = ax.scatter(\n",
    "        utm_coords[:, 0],\n",
    "        utm_coords[:, 1],\n",
    "        marker=\"o\",\n",
    "        c=colour_array,\n",
    "        s=4,\n",
    "        alpha=0.9,\n",
    "        transform=projection,\n",
    "        cmap=cm,\n",
    "    )\n",
    "\n",
    "    # set the colour bar ticks and labels\n",
    "    cb = plt.colorbar(sc, ticks=[0, 1])\n",
    "    cb.set_label(\"Magnetic units\" if \"Mag\" in theme else \"Free air Gravity (um/s^2)\")\n",
    "    cb.ax.set_yticklabels(\n",
    "        [str(np.min(variable)), str(np.max(variable))]\n",
    "    )  # vertically oriented colorbar\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_value_generator(\n",
    "    variable_name_list, dataset_list, bounding_box, min_points=None, max_points=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generator yielding coordinates and values of the specified variable\n",
    "    for all points from the supplied dataset list which fall within bounds\n",
    "    \"\"\"\n",
    "    line_dataset_count = 0\n",
    "    for dataset in dataset_list:\n",
    "        line_data = {}\n",
    "        try:\n",
    "            nc_dataset = netCDF4.Dataset(dataset)\n",
    "            # Note work-around for bad _FillValue: https://github.com/Unidata/netcdf-c/issues/1299\n",
    "            netcdf_point_utils = NetCDFPointUtils(nc_dataset)\n",
    "\n",
    "            # print netcdf_point_utils.__dict__\n",
    "            # print(nc_dataset.variables.keys())\n",
    "\n",
    "            # print('Computing spatial mask')\n",
    "            spatial_mask = netcdf_point_utils.get_spatial_mask(\n",
    "                bounding_box, bounds_wkt=netcdf_point_utils.wkt\n",
    "            )\n",
    "\n",
    "            point_count = np.count_nonzero(spatial_mask)\n",
    "\n",
    "            print(\n",
    "                f\"{point_count}/{netcdf_point_utils.point_count} points found in bounding box for {dataset}\"\n",
    "            )\n",
    "\n",
    "            if not point_count:\n",
    "                continue\n",
    "\n",
    "            # Enforce min/max point counts\n",
    "            if min_points and point_count < min_points:\n",
    "                print(f\"Skipping dataset with < {min_points} points\")\n",
    "                continue\n",
    "            if max_points and point_count > max_points:\n",
    "                print(f\"Skipping dataset with > {max_points} points\")\n",
    "                continue\n",
    "\n",
    "            dataset_value_dict = {\n",
    "                \"coordinates\": netcdf_point_utils.xycoords[spatial_mask]\n",
    "            }\n",
    "\n",
    "            # Read all variable attributes and values\n",
    "            for variable_name in variable_name_list:\n",
    "                variable = nc_dataset.variables[variable_name]\n",
    "                if variable.dimensions[0] != \"point\":\n",
    "                    # Variable is NOT of point dimension - must be lookup\n",
    "                    dataset_value_dict[\n",
    "                        variable_name\n",
    "                    ] = netcdf_point_utils.expand_lookup_variable(\n",
    "                        lookup_variable_name=variable_name, mask=spatial_mask\n",
    "                    )\n",
    "                else:  # 'point' is in variable.dimensions - \"normal\" variable\n",
    "                    dataset_value_dict[variable_name] = variable[:][spatial_mask]\n",
    "\n",
    "            yield dataset, dataset_value_dict\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Unable to read point dataset {}: {}\".format(dataset, e))\n",
    "\n",
    "            yield dataset, dataset_value_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all points in bounding box from NetCDF files in UTM projection\n",
    "# Lines will be filtered to exclude tielines by using \"flight_lines_only=True\"\n",
    "\n",
    "# dataset_values = {\n",
    "#     dataset: dataset_value_dict\n",
    "#     for dataset, dataset_value_dict in dataset_value_generator(\n",
    "#         [grid_var], files, GDA94_bounds #  [..., \"gridflag\"]\n",
    "#     )\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter points from individual datasets and plot their dataset name\n",
    "# # Only use points where gridflag == 'Station used in the production of GA grids.'\n",
    "# coordinate_list = []\n",
    "# value_list = []\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "# for dataset in sorted(dataset_values.keys()):\n",
    "#     coordinates = dataset_values[dataset][\"coordinates\"][:]\n",
    "#     if len(coordinates):\n",
    "#         coordinate_list.append(coordinates)\n",
    "#         value_list.append(dataset_values[dataset].get(grid_var))\n",
    "#         plt.plot(\n",
    "#             coordinates[:, 0],\n",
    "#             coordinates[:, 1],\n",
    "#             \".\",\n",
    "#             label=Path(dataset).name,\n",
    "#             markersize=0.05,\n",
    "#         )\n",
    "# plt.axis(\"equal\")\n",
    "# plt.legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doggo.registry_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = doggo.fetch(\"P738-line-magnetic-AWAGS_MAG_2010.nc\")\n",
    "# plot_survey_points(nc, grid_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single file gridding\n",
    "Following https://nbviewer.org/github/fatiando/data/blob/main/osborne-magnetic/prepare.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nc = xr.open_dataset(nc)\n",
    "\n",
    "data_full = pd.DataFrame({\n",
    "    \"longitude\": data_nc.longitude.data,\n",
    "    \"latitude\": data_nc.latitude.data,\n",
    "    \"terrain_clearance_m\": data_nc.altitude.data.astype(np.float32),\n",
    "    \"total_field_anomaly_nt\": data_nc.mag_awagsLevelled.data.astype(np.float32),\n",
    "    \"flight_line\": data_nc.line_index.data.astype(np.uint16),\n",
    "})\n",
    "\n",
    "# West, East, South, North\n",
    "selection = vd.inside((data_full.longitude, data_full.latitude), region)\n",
    "data = data_full[selection].reset_index(drop=True).copy()\n",
    "\n",
    "\n",
    "gda_to_wgs = pyproj.Transformer.from_crs(\"epsg:4283\", \"epsg:4326\", always_xy=True)\n",
    "longitude, latitude = gda_to_wgs.transform(\n",
    "    data.longitude.values, \n",
    "    data.latitude.values,\n",
    ")\n",
    "data = data.assign(longitude=longitude, latitude=latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srtm = vd.grid_to_table(pygmt.grdcut(\"@earth_relief_01s_g\", region=vd.pad_region(region, 2 / 60)))\n",
    "\n",
    "projection = pyproj.Proj(proj=\"merc\", lat_ts=data.latitude.mean())\n",
    "\n",
    "nearest = vd.ScipyGridder(method=\"nearest\")\n",
    "nearest.fit(projection(srtm.lon.values, srtm.lat.values), srtm.z)\n",
    "topography = nearest.predict(projection(data.longitude.values, data.latitude.values))\n",
    "\n",
    "data = data.assign(height_orthometric_m=topography + data.terrain_clearance_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = 3 / 3600\n",
    "reducer = vd.BlockReduce(np.median, spacing=spacing)\n",
    "coordinates, (total_field_anomaly, height) = reducer.filter(\n",
    "    (data.longitude, data.latitude), \n",
    "    (data.total_field_anomaly_nt, data.height_orthometric_m),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = (min(data.longitude), max(data.longitude), min(data.latitude), max(data.latitude))\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=1,\n",
    "    ncols=2,\n",
    "    figsize=(\"30c\", \"20c\"),\n",
    "    sharey=\"l\",  # shared y-axis on the left side\n",
    "    frame=\"WSrt\",\n",
    "):\n",
    "    with fig.set_panel(0):\n",
    "        fig.basemap(projection=\"M?\", region=region, frame=\"af\")\n",
    "        scale = 1500\n",
    "        pygmt.makecpt(cmap=\"polar+h\", series=[-scale, scale], background=True)\n",
    "        fig.plot(\n",
    "            x=coordinates[0],\n",
    "            y=coordinates[1],\n",
    "            color=total_field_anomaly,\n",
    "            style=\"c0.075c\",\n",
    "            cmap=True,\n",
    "        )\n",
    "        fig.colorbar(\n",
    "            frame='af+l\"total field magnetic anomaly [nT]\"', \n",
    "            position=\"JBC+h+o0/1c+e\",\n",
    "        )\n",
    "    with fig.set_panel(1):\n",
    "        fig.basemap(projection=\"M?\", region=region, frame=\"af\")\n",
    "        pygmt.makecpt(cmap=\"viridis\", series=[height.min(), height.max()])\n",
    "        fig.plot(\n",
    "            x=coordinates[0],\n",
    "            y=coordinates[1],\n",
    "            color=height,\n",
    "            style=\"c0.075c\",\n",
    "            cmap=True,\n",
    "        )\n",
    "        fig.colorbar(\n",
    "            frame='af+l\"observation height [m]\"', \n",
    "            position=\"JBC+h+o0/1c\",\n",
    "        )\n",
    "fig.savefig(\"preview.jpg\", dpi=200)\n",
    "fig.show(width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = pd.DataFrame({  \n",
    "    \"flight_line\": data.flight_line, \n",
    "    \"longitude\": data.longitude.map(lambda x: \"{:.5f}\".format(x)),\n",
    "    \"latitude\": data.latitude.map(lambda x: \"{:.5f}\".format(x)),    \n",
    "    \"height_orthometric_m\": data.height_orthometric_m.map(lambda x: \"{:.0f}\".format(x)),   \n",
    "    \"total_field_anomaly_nt\": data.total_field_anomaly_nt.map(lambda x: \"{:.0f}\".format(x)), \n",
    "})\n",
    "\n",
    "fname = \"osborne-magnetic.csv.xz\"\n",
    "export.to_csv(fname, index=False)\n",
    "\n",
    "for alg in [\"md5\", \"sha256\"]:\n",
    "    print(f\"{alg}:{pooch.file_hash(fname, alg=alg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LS\n",
    "lon = \"longitude\"  # .upper()\n",
    "lat = \"latitude\"  # .upper() # GDA94 latlon\n",
    "x = \"easting\"\n",
    "y = \"northing\"\n",
    "\n",
    "data_back = pd.read_csv(fname)\n",
    "spacing = 50 # meters\n",
    "grid_var = \"total_field_anomaly_nt\" if \"AWAGS\" in nc else \"freeair\"\n",
    "\n",
    "wgs_to_mga55 = Transformer.from_crs(\"epsg:4326\", \"epsg:28355\", always_xy=True)\n",
    "easting, northing = wgs_to_mga55.transform(data_back[lon], data_back[lat], errcheck=False)\n",
    "\n",
    "reducer = vd.BlockReduce(np.median, spacing=(spacing,))\n",
    "coordinates, (total_field_anomaly, height) = reducer.filter(\n",
    "    (easting, northing), \n",
    "    (data_back[grid_var], data_back[\"height_orthometric_m\"]),\n",
    ")\n",
    "\n",
    "# df = df_full.dropna()  # Some datasets have nans...\n",
    "# print(f\"Dropped {len(df_full) - len(df)} NaN points, kept {len(df)} points\")\n",
    "# proj_coords = (df[x].values, df[y].values)\n",
    "\n",
    "spline = vd.Spline().fit(coordinates, total_field_anomaly.astype(np.float32))\n",
    "grid = spline.grid(spacing=spacing, data_names=grid_var)\n",
    "\n",
    "grid = vd.distance_mask(coordinates, maxdist=spacing * 10, grid=grid)\n",
    "\n",
    "plt.figure(figsize=(10, 30), constrained_layout=True)\n",
    "plt.title(f\"Gridded {grid_var} in Cartesian coordinates\")\n",
    "pc = grid[grid_var].plot.pcolormesh(cmap=cc.cm.CET_L16, add_colorbar=True)\n",
    "plt.plot(coordinates[0], coordinates[1], \".k\", markersize=0.5)\n",
    "plt.xlabel(\"Easting (m)\")\n",
    "plt.ylabel(\"Northing (m)\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "tifffile.imwrite(\"test.tif\", grid[grid_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = vd.Chain(\n",
    "    [\n",
    "        (\"median\", vd.BlockReduce(np.median, spacing=spacing)),\n",
    "        #   (\"trend\", vd.Trend(degree=1)),\n",
    "        (\n",
    "            \"spline\",\n",
    "            vd.SplineCV(\n",
    "                dampings=[1e-6],  # 1e-10, 1e-1,\n",
    "                mindists=[1000],  # , 10e3\n",
    "                delayed=True,\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "train, test = vd.train_test_split(\n",
    "    (df.y, df.x), df.data, random_state=0, spacing=spacing\n",
    ")\n",
    "chain.fit(*train)\n",
    "score = chain.score(*test)\n",
    "\n",
    "print(\"\\nBest spline configuration:\")\n",
    "# print(f\"\\nScore: {chain.named_steps['spline'].scores_:.3f}\")\n",
    "print(\"mindist:\", chain.named_steps[\"spline\"].mindist_)\n",
    "print(\"damping:\", chain.named_steps[\"spline\"].damping_)\n",
    "\n",
    "grid_full = chain.grid(\n",
    "    # region=projection(*region),\n",
    "    spacing=spacing,\n",
    "    # projection=projection,\n",
    "    dims=[\"Easting\", \"Northing\"],\n",
    "    data_names=\"grid_var\",\n",
    ")\n",
    "\n",
    "chain_grid = vd.distance_mask((df.y, df.x), grid=grid_full, maxdist=spacing * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the grid and the original data points\n",
    "plt.figure(figsize=(10, 30), constrained_layout=True)\n",
    "plt.title(\"Gridded free air gravity in Cartesian coordinates\")\n",
    "pc = chain_grid[grid_var].plot.pcolormesh(cmap=cc.cm.CET_L16, add_colorbar=True)\n",
    "plt.scatter(df.y, df.x, c=\"k\", s=0.1)\n",
    "plt.xlabel(\"Easting (m)\")\n",
    "plt.ylabel(\"Northing (m)\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 20))\n",
    "plt.title(\n",
    "    f\"RMSE:{np.sqrt(np.nanmean((grid.freeair.values - chain_grid.freeair.values)**2))}\"\n",
    ")\n",
    "plt.imshow(\n",
    "    grid.freeair.values - chain_grid.freeair.values,\n",
    "    cmap=cc.cm.CET_D7,\n",
    "    vmin=-20,\n",
    "    vmax=20,\n",
    ")\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation Gridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_list = []\n",
    "value_list = []\n",
    "\n",
    "for dataset in sorted(dataset_values.keys()):\n",
    "    coordinates = dataset_values[dataset][\"coordinates\"][:]\n",
    "    if len(coordinates):\n",
    "        coordinate_list.extend(coordinates)\n",
    "        value_list.extend(dataset_values[dataset].get(grid_var))\n",
    "coordinate_list = np.array(coordinate_list)\n",
    "value_list = np.array(value_list)\n",
    "\n",
    "compilation_data = pd.DataFrame(\n",
    "    data={\n",
    "        \"latitude\": coordinate_list[:, 1],\n",
    "        \"longitude\": coordinate_list[:, 0],\n",
    "        \"freeair\": value_list,\n",
    "    }\n",
    ")\n",
    "data = compilation_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5cf9d43a7d23a32b291556ac896ae07d282e5749519878c10e69ed7ba2d1d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
